{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FarmWise: Farmland Segmentation and Size Classification with YOLOv8\n",
    "\n",
    "**Date**: April 14, 2025\n",
    "\n",
    "This notebook implements a farm segmentation system using the **YOLOv8** architecture to identify agricultural fields from satellite imagery, calculate their sizes, and classify them for targeted recommendations.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Goal**: Create a system that can:\n",
    "1. Detect and segment farmlands from satellite imagery\n",
    "2. Calculate the size/area of each identified farm\n",
    "3. Classify farms by size (small, medium, large)\n",
    "4. Enable a recommendation system based on farm size classification\n",
    "\n",
    "**Approach**: **YOLOv8** architecture for instance segmentation, leveraging transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Problem Statement\n",
    "\n",
    "Agricultural recommendations are most effective when tailored to the specific context of a farm, with farm size being a crucial factor. Large farms may benefit from different techniques, equipment, and crop selections compared to small ones. This project aims to automatically classify farms by size from satellite imagery to enable targeted recommendations.\n",
    "\n",
    "### 1.2 Success Criteria\n",
    "\n",
    "- **Technical Success**: Achieve high accuracy in farmland segmentation (e.g., mAP50-95 > 0.6 for segmentation)\n",
    "- **Business Success**: Enable accurate size-based classification of farms for targeted recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition and Understanding\n",
    "\n",
    "### 2.1 Setup and Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:27:59.558570Z",
     "iopub.status.busy": "2025-04-17T16:27:59.558392Z",
     "iopub.status.idle": "2025-04-17T16:29:18.348281Z",
     "shell.execute_reply": "2025-04-17T16:29:18.347481Z",
     "shell.execute_reply.started": "2025-04-17T16:27:59.558544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries, including ultralytics for YOLOv8\n",
    "!pip install torch torchvision matplotlib numpy pillow scikit-learn scikit-image opencv-python roboflow tqdm ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:29:18.352946Z",
     "iopub.status.busy": "2025-04-17T16:29:18.352442Z",
     "iopub.status.idle": "2025-04-17T16:29:22.152310Z",
     "shell.execute_reply": "2025-04-17T16:29:22.151514Z",
     "shell.execute_reply.started": "2025-04-17T16:29:18.352924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image as PILImage # Import PIL Image with an alias\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from tqdm.notebook import tqdm\n",
    "from roboflow import Roboflow\n",
    "import yaml\n",
    "import random\n",
    "from ultralytics import YOLO # Import YOLO\n",
    "import warnings # Import warnings module\n",
    "import pandas as pd # Import pandas for reading CSV\n",
    "import traceback # Import traceback module\n",
    "\n",
    "# Filter specific warning messages\n",
    "warnings.filterwarnings(\"ignore\", message=\".*validation plots.*items per image.*\")\n",
    "# Optional: Filter other common but less critical warnings if needed\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module='matplotlib')\n",
    "\n",
    "# Set random seeds for reproducibility (less critical for YOLO training but good practice)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check for GPU availability and set up device\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    gpu_indices = list(range(num_gpus))\n",
    "    for i in gpu_indices:\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    # Create device string for YOLO: '0' for one GPU, '0,1' for two, etc.\n",
    "    device = ','.join(map(str, gpu_indices)) if num_gpus > 0 else 'cpu'\n",
    "    print(f\"Using device string for YOLO: '{device}'\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"No GPU available, using CPU. Training will be significantly slower.\")\n",
    "\n",
    "# Display CUDA version if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Current CUDA device index: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Acquisition from Roboflow\n",
    "\n",
    "We acquire the dataset in YOLOv8 format, which includes images and corresponding text files with segmentation coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:29:22.155044Z",
     "iopub.status.busy": "2025-04-17T16:29:22.154601Z",
     "iopub.status.idle": "2025-04-17T16:30:20.803732Z",
     "shell.execute_reply": "2025-04-17T16:30:20.803146Z",
     "shell.execute_reply.started": "2025-04-17T16:29:22.155016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize Roboflow and load dataset\n",
    "# Note: You will need to provide your Roboflow API key\n",
    "try:\n",
    "    rf = Roboflow(api_key=\"HE9CEH5JxJ3U0vXrQTOy\")  # Replace with your actual API key\n",
    "    project = rf.workspace(\"sid-mp92l\").project(\"final-detectron-2\")\n",
    "    # Ensure the format is compatible with YOLOv8 segmentation (often 'yolov8' or similar)\n",
    "    dataset = project.version(1).download(\"yolov8\")\n",
    "    dataset_location = dataset.location\n",
    "    data_yaml_path = os.path.join(dataset_location, 'data.yaml')\n",
    "    print(f\"Dataset downloaded to: {dataset_location}\")\n",
    "    print(f\"Data YAML path: {data_yaml_path}\")\n",
    "    # Verify data.yaml exists\n",
    "    if not os.path.exists(data_yaml_path):\n",
    "        print(f\"\\nERROR: data.yaml not found at {data_yaml_path}. YOLOv8 training requires this file.\")\n",
    "        # Attempt to find it one level deeper if structure is nested\n",
    "        potential_yaml = os.path.join(dataset_location, project.name, 'data.yaml')\n",
    "        if os.path.exists(potential_yaml):\n",
    "             data_yaml_path = potential_yaml\n",
    "             print(f\"Found data.yaml at nested path: {data_yaml_path}\")\n",
    "        else:\n",
    "             data_yaml_path = None # Indicate failure\n",
    "             print(\"Please check the downloaded dataset structure.\")\n",
    "    else:\n",
    "        print(\"data.yaml found successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during Roboflow download or setup: {e}\")\n",
    "    print(\"Please ensure your API key is correct and the dataset exists.\")\n",
    "    dataset_location = None\n",
    "    data_yaml_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dataset Exploration\n",
    "\n",
    "Let's examine the structure of our dataset (downloaded in YOLOv8 format) and visualize some sample images with their annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:30:20.804773Z",
     "iopub.status.busy": "2025-04-17T16:30:20.804535Z",
     "iopub.status.idle": "2025-04-17T16:30:20.823726Z",
     "shell.execute_reply": "2025-04-17T16:30:20.823219Z",
     "shell.execute_reply.started": "2025-04-17T16:30:20.804743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Explore the dataset structure\n",
    "def explore_directory(path, level=0):\n",
    "    if not path or not os.path.isdir(path):\n",
    "        print(f\"Cannot explore path: {path}\")\n",
    "        return\n",
    "    print('  ' * level + f\"|-- {os.path.basename(path)}\")\n",
    "    try:\n",
    "        items = os.listdir(path)\n",
    "        for i, item in enumerate(items):\n",
    "            if i >= 10 and len(items) > 15: # Show first 10 and last 5 if many items\n",
    "                if i == 10:\n",
    "                     print('  ' * (level + 1) + f\"|-- ... ({len(items) - 15} more items) ...\")\n",
    "                elif i < len(items) - 5:\n",
    "                     continue\n",
    "            item_path = os.path.join(path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                explore_directory(item_path, level + 1)\n",
    "            else:\n",
    "                print('  ' * (level + 1) + f\"|-- {item}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exploring directory {path}: {e}\")\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "if dataset_location:\n",
    "    explore_directory(dataset_location)\n",
    "else:\n",
    "    print(\"Dataset location not defined. Cannot explore structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:30:20.824700Z",
     "iopub.status.busy": "2025-04-17T16:30:20.824460Z",
     "iopub.status.idle": "2025-04-17T16:30:22.366946Z",
     "shell.execute_reply": "2025-04-17T16:30:22.365903Z",
     "shell.execute_reply.started": "2025-04-17T16:30:20.824678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualization function remains largely the same, as it reads YOLO format files\n",
    "import yaml\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def visualize_yolo_segmentation_samples(data_dir, num_samples=3):\n",
    "    \"\"\"Visualizes original images and segmentation masks from YOLOv8 format annotations.\"\"\"\n",
    "    print(f\"\\n--- Starting Random Sample Visualization ({num_samples} samples) ---\")\n",
    "\n",
    "    if not data_dir or not os.path.isdir(data_dir):\n",
    "        print(f\"Error: Invalid data directory: {data_dir}\")\n",
    "        return\n",
    "\n",
    "    train_img_dir = os.path.join(data_dir, 'train', 'images')\n",
    "    train_label_dir = os.path.join(data_dir, 'train', 'labels')\n",
    "\n",
    "    if not os.path.isdir(train_img_dir):\n",
    "        print(f\"Error: Train image directory not found: {train_img_dir}\")\n",
    "        return\n",
    "    if not os.path.isdir(train_label_dir):\n",
    "        print(f\"Error: Train label directory not found: {train_label_dir}\")\n",
    "        return\n",
    "\n",
    "    img_files_all = [f for f in os.listdir(train_img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not img_files_all:\n",
    "        print(f\"No image files found in {train_img_dir}\")\n",
    "        return\n",
    "\n",
    "    num_available = len(img_files_all)\n",
    "    num_samples = min(num_samples, num_available)\n",
    "    if num_samples == 0:\n",
    "        print(\"No samples requested or available.\")\n",
    "        return\n",
    "    img_files = random.sample(img_files_all, num_samples)\n",
    "\n",
    "    yaml_path = os.path.join(data_dir, 'data.yaml')\n",
    "    class_names = ['Unknown']\n",
    "    if os.path.exists(yaml_path):\n",
    "        try:\n",
    "            with open(yaml_path, 'r') as f:\n",
    "                data_yaml = yaml.safe_load(f)\n",
    "            if 'names' in data_yaml:\n",
    "                class_names = data_yaml['names']\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error reading class names from data.yaml: {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: data.yaml not found at {yaml_path}.\")\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 6 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = np.array([axes]) # Ensure axes is always 2D\n",
    "    fig.suptitle(\"Random Sample Images and Ground Truth Segmentation Masks\", fontsize=16)\n",
    "\n",
    "    for i, img_file in enumerate(img_files):\n",
    "        ax_img, ax_mask = axes[i]\n",
    "        img_path = os.path.join(train_img_dir, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_np = np.array(img)\n",
    "            img_height, img_width = img_np.shape[:2]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_file}: {e}\")\n",
    "            ax_img.set_title(f\"Error loading {img_file}\")\n",
    "            ax_img.axis('off')\n",
    "            ax_mask.set_title(\"Mask N/A\")\n",
    "            ax_mask.axis('off')\n",
    "            continue\n",
    "\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(train_label_dir, label_file)\n",
    "        segmentation_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "        ax_img.imshow(img_np)\n",
    "        ax_img.set_title(f\"Image: {img_file}\")\n",
    "        ax_img.axis('off')\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            try:\n",
    "                with open(label_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                for line_idx, line in enumerate(lines):\n",
    "                    parts = line.strip().split(' ')\n",
    "                    if len(parts) < 5: continue # Need at least class + 2 points for segmentation\n",
    "                    class_id = int(parts[0])\n",
    "                    # Assuming polygon format: class x1 y1 x2 y2 ...\n",
    "                    if len(parts) % 2 == 1:\n",
    "                        polygon_points_normalized = []\n",
    "                        for j in range(1, len(parts), 2):\n",
    "                            if j + 1 < len(parts):\n",
    "                                try:\n",
    "                                    x_norm = float(parts[j])\n",
    "                                    y_norm = float(parts[j+1])\n",
    "                                    polygon_points_normalized.append((x_norm, y_norm))\n",
    "                                except ValueError:\n",
    "                                    print(f\"Warning: Invalid coordinate in {label_file}, line {line_idx+1}\")\n",
    "                                    polygon_points_normalized = [] # Reset for this line\n",
    "                                    break\n",
    "                        if len(polygon_points_normalized) >= 3:\n",
    "                            polygon_points_pixels = [(int(x*img_width), int(y*img_height)) for x,y in polygon_points_normalized]\n",
    "                            pts = np.array(polygon_points_pixels, np.int32).reshape((-1, 1, 2))\n",
    "                            cv2.fillPoly(segmentation_mask, [pts], 255) # Fill mask white\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing label file {label_file}: {e}\")\n",
    "                ax_mask.set_title(\"Error reading labels\")\n",
    "        else:\n",
    "            ax_mask.set_title(\"Label file missing\")\n",
    "\n",
    "        ax_mask.imshow(segmentation_mask, cmap='gray')\n",
    "        ax_mask.set_title(f\"Ground Truth Mask (from {label_file})\")\n",
    "        ax_mask.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    print(\"--- Finished Random Sample Visualization ---\")\n",
    "\n",
    "# Run the visualization\n",
    "if dataset_location:\n",
    "    try:\n",
    "        num_visual_samples = 3\n",
    "        visualize_yolo_segmentation_samples(dataset_location, num_samples=num_visual_samples)\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"An unexpected error occurred during visualization: {e}\")\n",
    "else:\n",
    "    print(\"\\nError: Dataset location not defined. Cannot run visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data Preparation\n",
    "\n",
    "The data downloaded from Roboflow in YOLOv8 format is already structured correctly for YOLOv8 training. It expects a specific directory structure (`train/images`, `train/labels`, `valid/images`, `valid/labels`) and a `data.yaml` file defining the paths and class names.\n",
    "\n",
    "We just need to ensure the `data.yaml` path is correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:30:22.368003Z",
     "iopub.status.busy": "2025-04-17T16:30:22.367741Z",
     "iopub.status.idle": "2025-04-17T16:30:22.375649Z",
     "shell.execute_reply": "2025-04-17T16:30:22.374749Z",
     "shell.execute_reply.started": "2025-04-17T16:30:22.367985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify the data.yaml path again and print its contents\n",
    "if data_yaml_path and os.path.exists(data_yaml_path):\n",
    "    print(f\"Using data configuration file: {data_yaml_path}\")\n",
    "    try:\n",
    "        with open(data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "        print(\"\\nContents of data.yaml:\")\n",
    "        print(yaml.dump(data_config))\n",
    "        \n",
    "        # Optional: Check if paths in data.yaml are relative/absolute and adjust if needed\n",
    "        # This might be necessary if the YAML paths are incorrect relative to the notebook's execution location\n",
    "        # Example check (adjust logic as needed):\n",
    "        # if not os.path.isabs(data_config['train']):\n",
    "        #    data_config['train'] = os.path.join(dataset_location, data_config['train'])\n",
    "        #    data_config['val'] = os.path.join(dataset_location, data_config['val'])\n",
    "        #    print(\"\\nAdjusted paths in data_config to be absolute (if necessary).\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or parsing data.yaml: {e}\")\n",
    "        data_yaml_path = None # Mark as invalid\n",
    "else:\n",
    "    print(\"ERROR: data.yaml path is not valid or file doesn't exist.\")\n",
    "    print(\"YOLOv8 training cannot proceed without a valid data.yaml file.\")\n",
    "    # You might need to manually create or correct the data.yaml file here\n",
    "    # It should look something like this:\n",
    "    # train: ../train/images\n",
    "    # val: ../valid/images\n",
    "    # \n",
    "    # nc: 1  # number of classes\n",
    "    # names: ['farm'] # class names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Removed Custom Dataset and DataLoader setup as YOLOv8 handles data loading internally based on `data.yaml`)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling with YOLOv8\n",
    "\n",
    "### 3.1 Transfer Learning with Pre-trained YOLOv8\n",
    "\n",
    "We will use a pre-trained YOLOv8 segmentation model (`yolov8n-seg.pt`) as a starting point. This leverages knowledge learned from a large dataset (COCO) and allows for faster convergence and better performance on our specific farmland segmentation task. This process is known as **transfer learning** or **fine-tuning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:30:22.376655Z",
     "iopub.status.busy": "2025-04-17T16:30:22.376443Z",
     "iopub.status.idle": "2025-04-17T16:30:24.078494Z",
     "shell.execute_reply": "2025-04-17T16:30:24.077868Z",
     "shell.execute_reply.started": "2025-04-17T16:30:22.376639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLOv8 segmentation model\n",
    "try:\n",
    "    # Choose a model size (n, s, m, l, x) - 'l' is large\n",
    "    model_name = 'yolov8l-seg.pt' # Changed to large model\n",
    "    model = YOLO(model_name)\n",
    "    print(f\"Successfully loaded pre-trained model: {model_name}\")\n",
    "    \n",
    "    # Move model to the appropriate device (handled internally by YOLO, but good to confirm)\n",
    "    # model.to(device) # YOLO handles device assignment during train/val/predict\n",
    "    print(f\"Model will use device(s): {device} during operations\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    print(\"Ensure 'ultralytics' is installed and the model name is correct.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Yes, the model loaded (`yolov8n-seg.pt`) is specifically a **segmentation** model provided by Ultralytics. It predicts both bounding boxes and pixel-level masks for detected objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training / Fine-tuning the Model\n",
    "\n",
    "We will now train (fine-tune) the pre-trained YOLOv8 model on our custom farmland dataset using the configuration specified in `data.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:30:24.079369Z",
     "iopub.status.busy": "2025-04-17T16:30:24.079162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 30  # Reduced number of epochs\n",
    "image_size = 640 # YOLOv8 default, adjust if needed\n",
    "batch_size = 16  # Reverted batch size for safety\n",
    "project_name = 'FarmWise_YOLOv8_Segmentation'\n",
    "run_name = 'initial_finetune_large_mem_optimized_aug'\n",
    "\n",
    "if model and data_yaml_path:\n",
    "    print(\"\\nStarting YOLOv8 training...\")\n",
    "    print(\"The output below will show progress per epoch, including:\")\n",
    "    print(\"- Epoch number\")\n",
    "    print(\"- Losses (box, segmentation, classification)\")\n",
    "    print(\"- Key metrics (e.g., mAP50, mAP50-95 for segmentation)\")\n",
    "    print(\"- Time per epoch\")\n",
    "    print(\"- Estimated time remaining (ETA)\")\n",
    "    try:\n",
    "        # Train the model\n",
    "        # verbose=True (default) provides detailed epoch-by-epoch updates including metrics and ETA.\n",
    "        results = model.train(\n",
    "            data=data_yaml_path, \n",
    "            epochs=num_epochs, \n",
    "            imgsz=image_size, \n",
    "            batch=batch_size, \n",
    "            device=device, # Pass the potentially multi-GPU device string\n",
    "            project=project_name, # Directory to save results\n",
    "            name=run_name, # Subdirectory for this specific run\n",
    "            exist_ok=True, # Allow overwriting previous runs with the same name\n",
    "            patience=10, # Early stopping patience\n",
    "            verbose=True, # Show detailed training progress (includes stats, metrics, ETA per epoch)\n",
    "            optimizer='AdamW', # Use AdamW optimizer for better performance\n",
    "            lr0=0.001, # Initial learning rate\n",
    "            lrf=0.01, # Final learning rate factor for cosine annealing scheduler\n",
    "            weight_decay=0.0005, # Weight decay for regularization\n",
    "            # Adjusted augmentation settings for lower memory\n",
    "            augment=True, \n",
    "            degrees=10.0, # Slightly reduced rotation\n",
    "            translate=0.1, # Slightly reduced translation\n",
    "            scale=0.5, # Keep scale\n",
    "            shear=3.0, # Slightly reduced shear\n",
    "            perspective=0.0001, # Reduced perspective\n",
    "            flipud=0.5, # Keep flip up-down\n",
    "            fliplr=0.5, # Keep flip left-right\n",
    "            mosaic=1.0, # Keep mosaic\n",
    "            mixup=0.05, # Slightly reduced mixup\n",
    "            copy_paste=0.0 # Disabled copy-paste (can be memory intensive)\n",
    "        )\n",
    "        print(\"\\nTraining completed.\")\n",
    "        print(f\"Results, logs, plots, and model weights saved to: {results.save_dir}\")\n",
    "        # The best model checkpoint is usually saved as 'best.pt' in the run directory's weights folder\n",
    "        best_model_path = os.path.join(results.save_dir, 'weights', 'best.pt')\n",
    "        if os.path.exists(best_model_path):\n",
    "             print(f\"Best model saved at: {best_model_path}\")\n",
    "        else:\n",
    "             print(f\"Could not find 'best.pt' in {os.path.join(results.save_dir, 'weights')}. Check training output.\")\n",
    "             # Fallback: try finding last.pt\n",
    "             last_model_path = os.path.join(results.save_dir, 'weights', 'last.pt')\n",
    "             if os.path.exists(last_model_path):\n",
    "                 print(f\"Using last model checkpoint: {last_model_path}\")\n",
    "                 best_model_path = last_model_path\n",
    "             else:\n",
    "                 best_model_path = None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during YOLOv8 training: {e}\")\n",
    "        traceback.print_exc()\n",
    "        best_model_path = None\n",
    "else:\n",
    "    print(\"\\nSkipping training: Model or data.yaml path not available.\")\n",
    "    best_model_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Output and Results\n",
    "\n",
    "The cell above displays the training progress live. For each epoch, you should see:\n",
    "*   Loss values (box, segmentation, classification)\n",
    "*   Segmentation metrics (mAP50, mAP50-95)\n",
    "*   Time taken for the epoch and estimated time remaining (ETA).\n",
    "\n",
    "All detailed results, including metrics plots (like loss curves, PR curves), confusion matrices, and saved model checkpoints (`best.pt`, `last.pt`), are stored in the directory printed at the end of the training output (e.g., `FarmWise_YOLOv8_Segmentation/initial_finetune/`). You can inspect these files for a comprehensive analysis after training completes.\n",
    "\n",
    "Let's display some of the key result plots generated during training, including the main results overview which contains loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results plots (including loss curves in results.png)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "if 'results' in locals() and hasattr(results, 'save_dir'):\n",
    "    results_dir = results.save_dir\n",
    "    print(f\"Displaying plots from: {results_dir}\")\n",
    "    \n",
    "    # Common plots saved by YOLOv8\n",
    "    # results.png contains training/validation loss and metrics curves\n",
    "    plot_files = [\n",
    "        'results.png', \n",
    "        'confusion_matrix.png', \n",
    "        'val_batch0_labels.jpg', # Example batch labels\n",
    "        'val_batch0_pred.jpg' # Example batch predictions\n",
    "    ]\n",
    "    \n",
    "    found_plots = False\n",
    "    for plot_file in plot_files:\n",
    "        plot_path = os.path.join(results_dir, plot_file)\n",
    "        if os.path.exists(plot_path):\n",
    "            print(f\"\\n--- {plot_file} ---\")\n",
    "            display(Image(filename=plot_path, width=800))\n",
    "            found_plots = True\n",
    "        else:\n",
    "            print(f\"Plot not found: {plot_path}\")\n",
    "            \n",
    "    if not found_plots:\n",
    "        print(\"Could not find standard result plots. Check the save directory.\")\n",
    "        # List files if needed:\n",
    "        # print(\"Files in results directory:\", os.listdir(results_dir))\n",
    "        \n",
    "else:\n",
    "    print(\"Training results object ('results') not found. Cannot display plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Loss Plots (Initial Training)\n",
    "\n",
    "We can also plot the individual loss components from the `results.csv` file for a more granular view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed losses from results.csv\n",
    "if 'results' in locals() and hasattr(results, 'save_dir'):\n",
    "    results_csv_path = os.path.join(results.save_dir, 'results.csv')\n",
    "    if os.path.exists(results_csv_path):\n",
    "        try:\n",
    "            df = pd.read_csv(results_csv_path)\n",
    "            # Clean column names (remove leading/trailing spaces)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot Training Losses\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(df['epoch'], df['train/box_loss'], label='Train Box Loss')\n",
    "            plt.plot(df['epoch'], df['train/seg_loss'], label='Train Seg Loss')\n",
    "            plt.plot(df['epoch'], df['train/cls_loss'], label='Train Cls Loss')\n",
    "            # DFL loss might not always be present, check first\n",
    "            if 'train/dfl_loss' in df.columns:\n",
    "                 plt.plot(df['epoch'], df['train/dfl_loss'], label='Train DFL Loss')\n",
    "            plt.title('Training Losses vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot Validation Losses\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(df['epoch'], df['val/box_loss'], label='Val Box Loss')\n",
    "            plt.plot(df['epoch'], df['val/seg_loss'], label='Val Seg Loss')\n",
    "            plt.plot(df['epoch'], df['val/cls_loss'], label='Val Cls Loss')\n",
    "            if 'val/dfl_loss' in df.columns:\n",
    "                 plt.plot(df['epoch'], df['val/dfl_loss'], label='Val DFL Loss')\n",
    "            plt.title('Validation Losses vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot mAP Metrics\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(df['epoch'], df['metrics/mAP50(M)'], label='mAP50 (Mask)')\n",
    "            plt.plot(df['epoch'], df['metrics/mAP50-95(M)'], label='mAP50-95 (Mask)')\n",
    "            plt.title('Segmentation mAP vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('mAP')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot Precision and Recall (Mask)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.plot(df['epoch'], df['metrics/precision(M)'], label='Precision (Mask)')\n",
    "            plt.plot(df['epoch'], df['metrics/recall(M)'], label='Recall (Mask)')\n",
    "            plt.title('Precision & Recall (Mask) vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting losses from CSV: {e}\")\n",
    "            # print(df.columns) # Uncomment to debug column names\n",
    "    else:\n",
    "        print(f\"results.csv not found at: {results_csv_path}\")\n",
    "else:\n",
    "    print(\"Training results object ('results') not found. Cannot plot detailed losses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Visualization\n",
    "\n",
    "Let's load our best fine-tuned model and evaluate its performance on the validation set using YOLOv8's built-in methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the best model for evaluation\n",
    "initial_map50_95 = None # Store initial metrics\n",
    "initial_map50 = None\n",
    "visualization_sample_images = [] # Store sample images for later comparison\n",
    "\n",
    "if 'best_model_path' not in locals(): # Define if training was skipped\n",
    "    # Attempt to manually define the path if needed, e.g. from a previous run\n",
    "    # Use the updated run_name from the training cell\n",
    "    potential_path = os.path.join(project_name, run_name, 'weights', 'best.pt')\n",
    "    if os.path.exists(potential_path):\n",
    "        best_model_path = potential_path\n",
    "        print(f\"Manually identified best model path: {best_model_path}\")\n",
    "    else:\n",
    "        best_model_path = None\n",
    "        print(\"best_model_path variable not found. Please ensure training ran or set the path manually.\")\n",
    "\n",
    "if best_model_path and os.path.exists(best_model_path):\n",
    "    print(f\"Loading best model from: {best_model_path}\")\n",
    "    try:\n",
    "        eval_model = YOLO(best_model_path)\n",
    "        print(\"Best model loaded successfully for evaluation.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best model: {e}\")\n",
    "        eval_model = None\n",
    "elif 'model' in locals() and model is not None: # Fallback to the model after initial loading if best.pt wasn't identified/trained\n",
    "    print(\"Warning: Best model path not found or invalid. Using initially loaded pre-trained model for evaluation structure.\")\n",
    "    eval_model = model \n",
    "else:\n",
    "    print(\"Error: No model available for evaluation.\")\n",
    "    eval_model = None\n",
    "\n",
    "# --- Evaluate the Model ---\n",
    "if eval_model and data_yaml_path:\n",
    "    print(\"\\nRunning validation on the loaded model...\")\n",
    "    try:\n",
    "        metrics = eval_model.val(\n",
    "            data=data_yaml_path,\n",
    "            imgsz=image_size,\n",
    "            batch=batch_size, # Use the reverted batch size\n",
    "            split='val', # Specify the split to evaluate (usually 'val' or 'test')\n",
    "            device=device, # Pass the potentially multi-GPU device string\n",
    "            project=project_name,\n",
    "            name=f'{run_name}_validation', # Save validation results separately\n",
    "            exist_ok=True,\n",
    "            plots=True # Ensure plots are generated during validation (default)\n",
    "            # iou=0.6 # Default IoU threshold for metrics calculation, adjust if needed\n",
    "            # conf=0.001 # Default confidence threshold for metrics calculation\n",
    "        )\n",
    "        print(\"\\nValidation complete.\")\n",
    "        print(\"Initial Model Segmentation Metrics:\")\n",
    "        # Access specific metrics (keys might vary slightly based on YOLO version)\n",
    "        # Common metrics for segmentation include mAP50-95(M) and mAP50(M)\n",
    "        initial_map50_95 = metrics.seg.map  # Store for comparison\n",
    "        initial_map50 = metrics.seg.map50 # Store for comparison\n",
    "        print(f\"  mAP50-95 (Mask): {initial_map50_95:.4f}\")\n",
    "        print(f\"  mAP50 (Mask):    {initial_map50:.4f}\")\n",
    "        # Check against success criteria (adjust metric as needed)\n",
    "        target_map = 0.6 # Example target mAP50-95\n",
    "        if initial_map50_95 > target_map:\n",
    "             print(f\"\\n✅ Success! Achieved target mAP50-95 > {target_map} (Actual: {initial_map50_95:.4f})\")\n",
    "        else:\n",
    "             print(f\"\\n❌ Target mAP50-95 > {target_map} not achieved (Actual: {initial_map50_95:.4f})\")\n",
    "             \n",
    "    except AttributeError:\n",
    "        print(\"\\nCould not access segmentation metrics (e.g., metrics.seg.map). This might happen if:\")\n",
    "        print(\"  - The loaded model is not a segmentation model.\")\n",
    "        print(\"  - Validation failed to produce segmentation results.\")\n",
    "        print(\"  - The Ultralytics API version has changed metric accessors.\")\n",
    "        print(\"  Check the 'metrics' object structure or validation logs.\")\n",
    "        # print(metrics) # Uncomment to inspect the metrics object\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during validation: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nSkipping evaluation: Model or data.yaml path not available.\")\n",
    "\n",
    "# --- Visualize Predictions ---\n",
    "if eval_model and dataset_location:\n",
    "    print(\"\\nVisualizing predictions on validation images...\")\n",
    "    val_img_dir = os.path.join(dataset_location, 'valid', 'images')\n",
    "    if os.path.isdir(val_img_dir):\n",
    "        val_images = [os.path.join(val_img_dir, f) for f in os.listdir(val_img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        num_viz_samples = min(10, len(val_images)) # Increased number of visualization samples\n",
    "        if num_viz_samples > 0:\n",
    "            # Store the sampled images for later use with the re-trained model\n",
    "            visualization_sample_images = random.sample(val_images, num_viz_samples)\n",
    "            print(f\"Selected {len(visualization_sample_images)} images for visualization comparison.\")\n",
    "            try:\n",
    "                # Run prediction with NMS settings to reduce overlap and specific confidence\n",
    "                pred_results = eval_model.predict(\n",
    "                    source=visualization_sample_images, # Use the stored list\n",
    "                    save=False, # Don't save individual prediction images by default\n",
    "                    show=False, # Don't display using cv2.imshow\n",
    "                    conf=0.5, # Confidence threshold for predictions\n",
    "                    iou=0.45, # Lower IoU threshold for NMS to reduce overlapping masks\n",
    "                    device=device # Pass the potentially multi-GPU device string\n",
    "                )\n",
    "                \n",
    "                # Plot results using matplotlib, hiding boxes and labels\n",
    "                print(f\"Displaying {len(pred_results)} prediction results (Initial Model - Masks Only):\")\n",
    "                for i, r in enumerate(pred_results):\n",
    "                    # Use plot() with boxes=False and labels=False\n",
    "                    im_bgr = r.plot(boxes=False, labels=False)  # BGR numpy array of predictions (masks only)\n",
    "                    im_rgb = PILImage.fromarray(im_bgr[..., ::-1]) # Convert BGR to RGB using PILImage\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 10))\n",
    "                    plt.imshow(im_rgb)\n",
    "                    plt.title(f\"Initial Model Prediction (Masks Only): {os.path.basename(visualization_sample_images[i])}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError during prediction or visualization: {e}\")\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print(\"No validation images found to visualize.\")\n",
    "    else:\n",
    "        print(f\"Validation image directory not found: {val_img_dir}\")\n",
    "else:\n",
    "    print(\"\\nSkipping prediction visualization: Model or dataset location not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Post-processing: Farm Size Calculation and Classification\n",
    "\n",
    "After segmenting the farms using the trained YOLOv8 model, we need to process the predicted masks to calculate the area of each farm and classify them based on size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "def calculate_farm_properties(predictions, confidence_threshold=0.5, min_area_pixels=100):\n",
    "    \"\"\"\n",
    "    Processes YOLOv8 prediction results to find farms, calculate their areas,\n",
    "    and classify their size.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of result objects from model.predict().\n",
    "        confidence_threshold (float): Minimum confidence for a detection.\n",
    "        min_area_pixels (int): Minimum pixel area to consider a segment a farm.\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries, each containing info for one image:\n",
    "        {'image_path': str, 'farms': [{'id': int, 'area_pixels': float, 'size_category': str, 'confidence': float, 'bbox': list}]}\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "    farm_class_index = 0 # Assuming 'farm' is the first class (index 0) in data.yaml. Adjust if necessary.\n",
    "    \n",
    "    print(f\"Processing {len(predictions)} prediction results...\")\n",
    "    \n",
    "    for i, result in enumerate(predictions):\n",
    "        image_path = result.path\n",
    "        image_farms = []\n",
    "        img_h, img_w = result.orig_shape # Original image dimensions\n",
    "        \n",
    "        if result.masks is None or result.boxes is None:\n",
    "            # print(f\"No masks or boxes found for {os.path.basename(image_path)}\")\n",
    "            results_list.append({'image_path': os.path.basename(image_path), 'farms': []})\n",
    "            continue\n",
    "            \n",
    "        masks = result.masks.data.cpu().numpy() # (N, H, W) tensor of masks\n",
    "        boxes = result.boxes.data.cpu().numpy() # (N, 6) tensor [x1, y1, x2, y2, conf, cls]\n",
    "        \n",
    "        # print(f\"Processing {os.path.basename(image_path)}: Found {len(boxes)} detections.\")\n",
    "        \n",
    "        farm_id_counter = 0\n",
    "        for j in range(len(boxes)):\n",
    "            confidence = boxes[j, 4]\n",
    "            class_id = int(boxes[j, 5])\n",
    "            \n",
    "            # Filter by confidence and class (assuming farm is class 0)\n",
    "            if confidence >= confidence_threshold and class_id == farm_class_index:\n",
    "                mask = masks[j]\n",
    "                # Resize mask to original image size if necessary (YOLO might predict on resized)\n",
    "                if mask.shape[0] != img_h or mask.shape[1] != img_w:\n",
    "                     mask = cv2.resize(mask, (img_w, img_h), interpolation=cv2.INTER_NEAREST)\n",
    "                     \n",
    "                # Calculate area (number of positive pixels in the mask)\n",
    "                area_pixels = np.sum(mask > 0.5) # Use 0.5 threshold on mask probabilities\n",
    "                \n",
    "                if area_pixels >= min_area_pixels:\n",
    "                    farm_id_counter += 1\n",
    "                    bbox_xyxy = boxes[j, :4].tolist() # [x1, y1, x2, y2]\n",
    "                    \n",
    "                    # --- Size Classification (Example thresholds - adjust based on needs) ---\n",
    "                    if area_pixels < 5000:\n",
    "                        size_category = 'Small'\n",
    "                    elif area_pixels < 20000:\n",
    "                        size_category = 'Medium'\n",
    "                    else:\n",
    "                        size_category = 'Large'\n",
    "                        \n",
    "                    image_farms.append({\n",
    "                        'id': farm_id_counter,\n",
    "                        'area_pixels': area_pixels,\n",
    "                        'size_category': size_category,\n",
    "                        'confidence': float(confidence),\n",
    "                        'bbox': bbox_xyxy\n",
    "                    })\n",
    "                    # print(f\"  Farm {farm_id_counter}: Area={area_pixels}px, Class={size_category}, Conf={confidence:.2f}\")\n",
    "                # else:\n",
    "                    # print(f\"  Skipping detection {j}: Area {area_pixels}px < {min_area_pixels}px\")\n",
    "            # else:\n",
    "                # print(f\"  Skipping detection {j}: Conf {confidence:.2f} or Class {class_id} != {farm_class_index}\")\n",
    "                \n",
    "        results_list.append({'image_path': os.path.basename(image_path), 'farms': image_farms})\n",
    "        # Optional: Reduce verbosity during post-processing\n",
    "        # if not image_farms:\n",
    "        #      print(f\"No farms meeting criteria found in {os.path.basename(image_path)}\")\n",
    "        # else:\n",
    "        #      print(f\"Found {len(image_farms)} farms in {os.path.basename(image_path)}\")\n",
    "             \n",
    "    return results_list\n",
    "\n",
    "# --- Run Post-processing on the visualized predictions ---\n",
    "# Ensure pred_results exists from the visualization cell\n",
    "if 'pred_results' in locals() and pred_results:\n",
    "    print(\"\\nCalculating farm sizes and categories for visualized samples...\")\n",
    "    farm_data = calculate_farm_properties(pred_results, confidence_threshold=0.5, min_area_pixels=500)\n",
    "    \n",
    "    # Display calculated data\n",
    "    import json\n",
    "    print(\"\\n--- Farm Size Calculation Results ---\")\n",
    "    for img_result in farm_data:\n",
    "        print(f\"Image: {img_result['image_path']}\")\n",
    "        if img_result['farms']:\n",
    "            for farm in img_result['farms']:\n",
    "                print(f\"  - Farm ID: {farm['id']}, Area: {farm['area_pixels']:.0f} pixels, Category: {farm['size_category']}, Confidence: {farm['confidence']:.2f}\")\n",
    "        else:\n",
    "            print(\"  No farms detected or meeting criteria.\")\n",
    "        print(\"---\")\n",
    "else:\n",
    "    print(\"\\nSkipping farm size calculation: No prediction results available from the previous cell.\")\n",
    "    print(\"Ensure the 'Visualize Predictions' part of the evaluation cell ran successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Continued Fine-tuning (Transfer Learning from Fine-tuned Model)\n",
    "\n",
    "Based on the evaluation results, we might want to continue training the model for more epochs or with adjusted hyperparameters (like a lower learning rate) starting from the best checkpoint achieved in the previous training run (`best.pt`). This allows the model to potentially refine its weights further on the specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Continued Fine-tuning ---\n",
    "\n",
    "# Ensure the path to the best model from the *previous* run is available\n",
    "# This path was determined in the evaluation cell (cell ID 92c2a746)\n",
    "if 'best_model_path' in locals() and best_model_path and os.path.exists(best_model_path):\n",
    "    print(f\"Loading model for continued fine-tuning from: {best_model_path}\")\n",
    "    try:\n",
    "        # Load the previously fine-tuned model\n",
    "        continued_model = YOLO(best_model_path)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        \n",
    "        # Define parameters for the continued training run\n",
    "        continued_epochs = 15 # Number of *additional* epochs (reduced)\n",
    "        continued_run_name = 'continued_finetune_large_mem_optimized_aug'\n",
    "        # Optional: Adjust learning rate (often lower for continued tuning)\n",
    "        continued_lr0 = 0.0001 # Example: Lower learning rate\n",
    "        continued_lrf = 0.01 # Final LR factor for cosine schedule\n",
    "        \n",
    "        print(f\"\\nStarting continued fine-tuning for {continued_epochs} additional epochs...\")\n",
    "        \n",
    "        # Train again, starting from the loaded weights\n",
    "        continued_results = continued_model.train(\n",
    "            data=data_yaml_path, \n",
    "            epochs=num_epochs + continued_epochs, # Total epochs = original + additional\n",
    "            imgsz=image_size, \n",
    "            batch=batch_size, # Use same reverted batch size\n",
    "            device=device, \n",
    "            project=project_name, \n",
    "            name=continued_run_name, # Save to a new run directory\n",
    "            exist_ok=True, \n",
    "            patience=10, # Consider increasing patience if validation loss is still decreasing slowly\n",
    "            verbose=True, # Set back to True to monitor continued training\n",
    "            # Pass adjusted hyperparameters:\n",
    "            lr0=continued_lr0, \n",
    "            lrf=continued_lrf,\n",
    "            weight_decay=0.0005, \n",
    "            # Re-apply adjusted augmentation settings\n",
    "            augment=True,\n",
    "            degrees=10.0,\n",
    "            translate=0.1,\n",
    "            scale=0.5,\n",
    "            shear=3.0,\n",
    "            perspective=0.0001,\n",
    "            flipud=0.5,\n",
    "            fliplr=0.5,\n",
    "            mosaic=1.0,\n",
    "            mixup=0.05,\n",
    "            copy_paste=0.0,\n",
    "            resume=False # Start training from the loaded weights, don't resume an interrupted run\n",
    "        )\n",
    "        \n",
    "        print(\"\\nContinued fine-tuning completed.\")\n",
    "        print(f\"Results saved to: {continued_results.save_dir}\")\n",
    "        # Update best_model_path to the newly trained best model if needed for subsequent steps\n",
    "        new_best_model_path = os.path.join(continued_results.save_dir, 'weights', 'best.pt')\n",
    "        if os.path.exists(new_best_model_path):\n",
    "             print(f\"New best model saved at: {new_best_model_path}\")\n",
    "             # Store the path specifically for the continued model\n",
    "             continued_best_model_path = new_best_model_path \n",
    "             # Optionally update the main best_model_path if this is now considered the best overall\n",
    "             # best_model_path = new_best_model_path \n",
    "        else:\n",
    "             print(f\"Could not find 'best.pt' in {os.path.join(continued_results.save_dir, 'weights')}. Check training output.\")\n",
    "             continued_best_model_path = None # Indicate failure\n",
    "             \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during continued fine-tuning: {e}\")\n",
    "        traceback.print_exc()\n",
    "        continued_best_model_path = None\n",
    "        \n",
    "elif not data_yaml_path:\n",
    "     print(\"\\nSkipping continued fine-tuning: data.yaml path not available.\")\n",
    "     continued_best_model_path = None\n",
    "else:\n",
    "    print(\"\\nSkipping continued fine-tuning: 'best_model_path' from the previous run is not defined or the file does not exist.\")\n",
    "    print(\"Please ensure the initial training and evaluation steps completed successfully and 'best.pt' was saved.\")\n",
    "    continued_best_model_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued Training Results Plots\n",
    "\n",
    "Let's display the key result plots from the continued training run, including the main results overview which contains loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display continued training results plots (including loss curves in results.png)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "if 'continued_results' in locals() and hasattr(continued_results, 'save_dir'):\n",
    "    continued_results_dir = continued_results.save_dir\n",
    "    print(f\"Displaying plots from: {continued_results_dir}\")\n",
    "    \n",
    "    # Common plots saved by YOLOv8\n",
    "    # results.png contains training/validation loss and metrics curves\n",
    "    plot_files = [\n",
    "        'results.png', \n",
    "        'confusion_matrix.png', \n",
    "        'val_batch0_labels.jpg', # Example batch labels\n",
    "        'val_batch0_pred.jpg' # Example batch predictions\n",
    "    ]\n",
    "    \n",
    "    found_plots = False\n",
    "    for plot_file in plot_files:\n",
    "        plot_path = os.path.join(continued_results_dir, plot_file)\n",
    "        if os.path.exists(plot_path):\n",
    "            print(f\"\\n--- {plot_file} ---\")\n",
    "            display(Image(filename=plot_path, width=800))\n",
    "            found_plots = True\n",
    "        else:\n",
    "            print(f\"Plot not found: {plot_path}\")\n",
    "            \n",
    "    if not found_plots:\n",
    "        print(\"Could not find standard result plots. Check the save directory.\")\n",
    "        # List files if needed:\n",
    "        # print(\"Files in results directory:\", os.listdir(continued_results_dir))\n",
    "        \n",
    "else:\n",
    "    print(\"Continued training results object ('continued_results') not found. Cannot display plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Loss Plots (Continued Training)\n",
    "\n",
    "Plotting the individual loss components from the `results.csv` file for the continued training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed losses from continued training results.csv\n",
    "if 'continued_results' in locals() and hasattr(continued_results, 'save_dir'):\n",
    "    continued_results_csv_path = os.path.join(continued_results.save_dir, 'results.csv')\n",
    "    if os.path.exists(continued_results_csv_path):\n",
    "        try:\n",
    "            df_cont = pd.read_csv(continued_results_csv_path)\n",
    "            # Clean column names (remove leading/trailing spaces)\n",
    "            df_cont.columns = df_cont.columns.str.strip()\n",
    "            \n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot Training Losses\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(df_cont['epoch'], df_cont['train/box_loss'], label='Train Box Loss')\n",
    "            plt.plot(df_cont['epoch'], df_cont['train/seg_loss'], label='Train Seg Loss')\n",
    "            plt.plot(df_cont['epoch'], df_cont['train/cls_loss'], label='Train Cls Loss')\n",
    "            if 'train/dfl_loss' in df_cont.columns:\n",
    "                 plt.plot(df_cont['epoch'], df_cont['train/dfl_loss'], label='Train DFL Loss')\n",
    "            plt.title('Continued Training Losses vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot Validation Losses\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(df_cont['epoch'], df_cont['val/box_loss'], label='Val Box Loss')\n",
    "            plt.plot(df_cont['epoch'], df_cont['val/seg_loss'], label='Val Seg Loss')\n",
    "            plt.plot(df_cont['epoch'], df_cont['val/cls_loss'], label='Val Cls Loss')\n",
    "            if 'val/dfl_loss' in df_cont.columns:\n",
    "                 plt.plot(df_cont['epoch'], df_cont['val/dfl_loss'], label='Val DFL Loss')\n",
    "            plt.title('Continued Validation Losses vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot mAP Metrics\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(df_cont['epoch'], df_cont['metrics/mAP50(M)'], label='mAP50 (Mask)')\n",
    "            plt.plot(df_cont['epoch'], df_cont['metrics/mAP50-95(M)'], label='mAP50-95 (Mask)')\n",
    "            plt.title('Continued Segmentation mAP vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('mAP')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Plot Precision and Recall (Mask)\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.plot(df_cont['epoch'], df_cont['metrics/precision(M)'], label='Precision (Mask)')\n",
    "            plt.plot(df_cont['epoch'], df_cont['metrics/recall(M)'], label='Recall (Mask)')\n",
    "            plt.title('Continued Precision & Recall (Mask) vs. Epochs')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting continued losses from CSV: {e}\")\n",
    "            # print(df_cont.columns) # Uncomment to debug column names\n",
    "    else:\n",
    "        print(f\"Continued results.csv not found at: {continued_results_csv_path}\")\n",
    "else:\n",
    "    print(\"Continued training results object ('continued_results') not found. Cannot plot detailed losses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation and Comparison of Re-trained Model\n",
    "\n",
    "Now, let's evaluate the model that underwent continued fine-tuning and compare its performance metrics and prediction visualizations against the initial fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Evaluate the Re-trained Model ---\n",
    "continued_map50_95 = None\n",
    "continued_map50 = None\n",
    "\n",
    "# Check if the continued training produced a best model path\n",
    "if 'continued_best_model_path' in locals() and continued_best_model_path and os.path.exists(continued_best_model_path):\n",
    "    print(f\"Loading re-trained model from: {continued_best_model_path}\")\n",
    "    try:\n",
    "        retrained_eval_model = YOLO(continued_best_model_path)\n",
    "        print(\"Re-trained model loaded successfully for evaluation.\")\n",
    "        \n",
    "        if data_yaml_path:\n",
    "            print(\"\\nRunning validation on the re-trained model...\")\n",
    "            retrained_metrics = retrained_eval_model.val(\n",
    "                data=data_yaml_path,\n",
    "                imgsz=image_size,\n",
    "                batch=batch_size, # Use same reverted batch size\n",
    "                split='val',\n",
    "                device=device,\n",
    "                project=project_name,\n",
    "                name=f'{continued_run_name}_validation', # Save to a new validation folder\n",
    "                exist_ok=True,\n",
    "                plots=True # Ensure plots are generated during validation (default)\n",
    "                # iou=0.6 # Default IoU threshold for metrics calculation\n",
    "                # conf=0.001 # Default confidence threshold for metrics calculation\n",
    "            )\n",
    "            print(\"\\nRe-trained Model Validation complete.\")\n",
    "            print(\"Re-trained Model Segmentation Metrics:\")\n",
    "            continued_map50_95 = retrained_metrics.seg.map\n",
    "            continued_map50 = retrained_metrics.seg.map50\n",
    "            print(f\"  mAP50-95 (Mask): {continued_map50_95:.4f}\")\n",
    "            print(f\"  mAP50 (Mask):    {continued_map50:.4f}\")\n",
    "        else:\n",
    "            print(\"Skipping re-trained model validation: data.yaml path not available.\")\n",
    "            retrained_eval_model = None # Cannot evaluate\n",
    "            \n",
    "    except AttributeError:\n",
    "        print(\"\\nCould not access segmentation metrics (e.g., retrained_metrics.seg.map). This might happen if:\")\n",
    "        print(\"  - The loaded model is not a segmentation model.\")\n",
    "        print(\"  - Validation failed to produce segmentation results.\")\n",
    "        print(\"  - The Ultralytics API version has changed metric accessors.\")\n",
    "        print(\"  Check the 'retrained_metrics' object structure or validation logs.\")\n",
    "        # print(retrained_metrics) # Uncomment to inspect the metrics object\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or validating re-trained model: {e}\")\n",
    "        retrained_eval_model = None\n",
    "else:\n",
    "    print(\"Skipping re-trained model evaluation: Path 'continued_best_model_path' not found or invalid.\")\n",
    "    retrained_eval_model = None\n",
    "\n",
    "# --- Compare Metrics ---\n",
    "print(\"\\n--- Metrics Comparison ---\")\n",
    "if 'initial_map50_95' in locals() and initial_map50_95 is not None and \\\n",
    "   'continued_map50_95' in locals() and continued_map50_95 is not None and \\\n",
    "   'initial_map50' in locals() and initial_map50 is not None and \\\n",
    "   'continued_map50' in locals() and continued_map50 is not None:\n",
    "    print(f\"                     Initial Model | Re-trained Model\")\n",
    "    print(f\"mAP50-95 (Mask):      {initial_map50_95:^13.4f} | {continued_map50_95:^16.4f}\")\n",
    "    print(f\"mAP50 (Mask):         {initial_map50:^13.4f} | {continued_map50:^16.4f}\")\n",
    "    delta_map50_95 = continued_map50_95 - initial_map50_95\n",
    "    delta_map50 = continued_map50 - initial_map50\n",
    "    print(f\"Delta (Re-trained - Initial):\")\n",
    "    print(f\"  Δ mAP50-95: {delta_map50_95:+.4f}\")\n",
    "    print(f\"  Δ mAP50:    {delta_map50:+.4f}\")\n",
    "else:\n",
    "    print(\"Could not compare metrics. Ensure both initial and continued evaluations ran successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Visualize Re-trained Model Predictions (on the same images) ---\n",
    "if 'retrained_eval_model' in locals() and retrained_eval_model and 'visualization_sample_images' in locals() and visualization_sample_images:\n",
    "    print(\"\\nVisualizing predictions from re-trained model on the same sample images...\")\n",
    "    try:\n",
    "        # Run prediction with the re-trained model using same NMS/conf settings\n",
    "        retrained_pred_results = retrained_eval_model.predict(\n",
    "            source=visualization_sample_images, # Use the SAME images stored earlier\n",
    "            save=False,\n",
    "            show=False,\n",
    "            conf=0.5, \n",
    "            iou=0.45, # Use same NMS threshold\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Plot results using matplotlib, hiding boxes and labels\n",
    "        print(f\"Displaying {len(retrained_pred_results)} prediction results (Re-trained Model - Masks Only):\")\n",
    "        for i, r in enumerate(retrained_pred_results):\n",
    "            # Use plot() with boxes=False and labels=False\n",
    "            im_bgr = r.plot(boxes=False, labels=False)  \n",
    "            im_rgb = PILImage.fromarray(im_bgr[..., ::-1]) # Convert BGR to RGB using PILImage\n",
    "            \n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(im_rgb)\n",
    "            plt.title(f\"Re-trained Model Prediction (Masks Only): {os.path.basename(visualization_sample_images[i])}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during re-trained model prediction or visualization: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nSkipping re-trained prediction visualization: Re-trained model or sample image list not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing on Re-trained Model Results\n",
    "\n",
    "Let's apply the same farm size calculation and classification to the predictions made by the re-trained model to see the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run Post-processing on the re-trained predictions ---\n",
    "if 'retrained_pred_results' in locals() and retrained_pred_results:\n",
    "    print(\"\\nCalculating farm sizes and categories for re-trained model samples...\")\n",
    "    retrained_farm_data = calculate_farm_properties(retrained_pred_results, confidence_threshold=0.5, min_area_pixels=500)\n",
    "    \n",
    "    # Display calculated data\n",
    "    import json\n",
    "    print(\"\\n--- Re-trained Model Farm Size Calculation Results ---\")\n",
    "    for img_result in retrained_farm_data:\n",
    "        print(f\"Image: {img_result['image_path']}\")\n",
    "        if img_result['farms']:\n",
    "            for farm in img_result['farms']:\n",
    "                print(f\"  - Farm ID: {farm['id']}, Area: {farm['area_pixels']:.0f} pixels, Category: {farm['size_category']}, Confidence: {farm['confidence']:.2f}\")\n",
    "        else:\n",
    "            print(\"  No farms detected or meeting criteria.\")\n",
    "        print(\"---\")\n",
    "else:\n",
    "    print(\"\\nSkipping re-trained farm size calculation: No prediction results available from the re-trained model visualization cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison Summary\n",
    "\n",
    "This section summarizes the performance difference between the initial fine-tuned model and the model after continued fine-tuning. Review the metrics comparison table and the side-by-side visualizations generated in the previous section (Section 7).\n",
    "\n",
    "**Key aspects to compare:**\n",
    "\n",
    "*   **Metrics**: Did the mAP scores (mAP50-95 and mAP50) improve after continued fine-tuning? A positive delta indicates improvement.\n",
    "*   **Visualizations**: Compare the segmentation masks produced by the initial model and the re-trained model for the same images. Look for:\n",
    "    *   More accurate boundaries around farms.\n",
    "    *   Fewer false positives (incorrectly identified areas).\n",
    "    *   Fewer false negatives (missed farms).\n",
    "    *   Better separation of adjacent farms.\n",
    "\n",
    "Based on this comparison, decide if the continued fine-tuning was beneficial and if further training or hyperparameter adjustments are needed.\n",
    "\n",
    "Below, we re-display the calculated metrics for easy reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Re-display Metrics Comparison ---\n",
    "print(\"\\n--- Metrics Comparison (from Section 7) ---\")\n",
    "if 'initial_map50_95' in locals() and initial_map50_95 is not None and \\\n",
    "   'continued_map50_95' in locals() and continued_map50_95 is not None and \\\n",
    "   'initial_map50' in locals() and initial_map50 is not None and \\\n",
    "   'continued_map50' in locals() and continued_map50 is not None:\n",
    "    print(f\"                     Initial Model | Re-trained Model\")\n",
    "    print(f\"mAP50-95 (Mask):      {initial_map50_95:^13.4f} | {continued_map50_95:^16.4f}\")\n",
    "    print(f\"mAP50 (Mask):         {initial_map50:^13.4f} | {continued_map50:^16.4f}\")\n",
    "    delta_map50_95 = continued_map50_95 - initial_map50_95\n",
    "    delta_map50 = continued_map50 - initial_map50\n",
    "    print(f\"Delta (Re-trained - Initial):\")\n",
    "    print(f\"  Δ mAP50-95: {delta_map50_95:+.4f}\")\n",
    "    print(f\"  Δ mAP50:    {delta_map50:+.4f}\")\n",
    "else:\n",
    "    print(\"Metrics data not available. Ensure Section 7 (Evaluation and Comparison) ran successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Export for Deployment (e.g., Kaggle)\n",
    "\n",
    "Finally, let's export the best performing model (likely the one after continued fine-tuning) to a standard format like ONNX. This format is widely supported and suitable for deployment in various environments, including Kaggle notebooks or custom applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export the Final Model ---\n",
    "\n",
    "# Determine the path to the final best model (prefer the continued one if it exists and performed better)\n",
    "final_model_path = None\n",
    "export_run_name = None\n",
    "\n",
    "# Check if continued training happened and produced a model\n",
    "continued_exists = 'continued_best_model_path' in locals() and continued_best_model_path and os.path.exists(continued_best_model_path)\n",
    "initial_exists = 'best_model_path' in locals() and best_model_path and os.path.exists(best_model_path)\n",
    "\n",
    "if continued_exists:\n",
    "    # Optional: Add logic here to compare continued_map50_95 and initial_map50_95 if both exist\n",
    "    # For now, assume continued is preferred if it exists\n",
    "    final_model_path = continued_best_model_path\n",
    "    # Use the correct run name for the continued run\n",
    "    export_run_name = continued_run_name if 'continued_run_name' in locals() else 'continued_run'\n",
    "    print(f\"Selected the re-trained model for export: {final_model_path}\")\n",
    "elif initial_exists:\n",
    "    final_model_path = best_model_path\n",
    "    # Use the correct run name for the initial run\n",
    "    export_run_name = run_name if 'run_name' in locals() else 'initial_run'\n",
    "    print(f\"Selected the initial fine-tuned model for export (re-trained model not found/available): {final_model_path}\")\n",
    "else:\n",
    "    print(\"Error: No valid '.pt' model path found to export. Ensure at least one training run completed successfully.\")\n",
    "\n",
    "if final_model_path:\n",
    "    try:\n",
    "        print(\"\\nLoading the final model for export...\")\n",
    "        export_model = YOLO(final_model_path)\n",
    "        \n",
    "        # Define export parameters\n",
    "        export_format = 'onnx' # Other options: 'torchscript', 'engine', 'pb', etc.\n",
    "        # The export path will be relative to the notebook or you can specify an absolute path\n",
    "        # It usually saves within the last run's directory or you can specify opset\n",
    "        # Add nms=True to include NMS operations in the exported graph if supported\n",
    "        export_path = export_model.export(\n",
    "            format=export_format, \n",
    "            imgsz=image_size, \n",
    "            opset=12, # Common opset for compatibility\n",
    "            nms=True # Include NMS in the export if possible\n",
    "            # Note: Specific NMS parameters like iou/conf are typically applied during inference runtime, not baked into the ONNX model itself.\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nModel successfully exported to {export_format} format.\")\n",
    "        print(f\"Exported model saved at: {export_path}\")\n",
    "        print(f\"\\nYou can now use the file '{export_path}' for deployment.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during model export: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nSkipping model export.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
