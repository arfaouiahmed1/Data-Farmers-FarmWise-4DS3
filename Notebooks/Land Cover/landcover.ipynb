# DeepGlobe Land Cover Classification using U-Net

**Objective:** This notebook implements a U-Net based deep learning model for semantic segmentation of land cover types using the DeepGlobe Land Cover Classification dataset.

**Methodology:**
1.  **Data Loading & Preprocessing:** Load image paths and corresponding segmentation masks from the dataset. Preprocess images (resizing, normalization) and masks (resizing, converting RGB color codes to class indices, one-hot encoding). Utilize `tf.data` for efficient data handling pipelines.
2.  **Model Definition:** Define a U-Net architecture, a standard convolutional neural network for biomedical image segmentation, adapted here for satellite imagery.
3.  **Model Training:** Train the U-Net model using the preprocessed data, employing appropriate loss functions (Categorical Crossentropy), optimizers (Adam), and metrics (Accuracy, Mean Intersection over Union - MeanIoU). Use callbacks for saving the best model, early stopping, and learning rate reduction.
4.  **Evaluation:** Evaluate the trained model on a validation set using loss, accuracy, and MeanIoU.
5.  **Visualization:** Visualize the training progress (loss, accuracy, MeanIoU curves) and compare predicted segmentation masks against the ground truth masks for qualitative assessment. Include a confusion matrix for quantitative class-wise performance analysis.

**Dataset:**
*   **Source:** [DeepGlobe Land Cover Classification Challenge](https://competitions.codalab.org/competitions/18468) (Requires accessing the data, e.g., via Kaggle datasets: `/kaggle/input/deepglobe-land-cover-classification-dataset/`)
*   **Content:** Satellite images (`_sat.jpg`) and corresponding manually annotated segmentation masks (`_mask.png`).
*   **Classes:** The masks use specific RGB colors to represent different land cover types. This notebook maps these colors to integer class labels.

**Libraries:** TensorFlow/Keras, NumPy, Pandas, Matplotlib, Scikit-learn.
"""

# ## 1. Setup and Imports
#
# Import necessary libraries and define constants.

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.metrics import MeanIoU
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import seaborn as sns
from matplotlib.colors import ListedColormap, BoundaryNorm

# Set random seeds for reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

# --- Constants ---

# Image Dimensions
IMG_HEIGHT = 256
IMG_WIDTH = 256
IMG_CHANNELS = 3 # RGB Images

# Dataset Specifics
# Check dataset documentation for the correct number of classes
# Typically 6 classes + 1 background/unknown = 7
NUM_CLASSES = 7

# Training Hyperparameters
BATCH_SIZE = 16      # Adjust based on available GPU memory (e.g., T4/P100 on Kaggle/Colab)
BUFFER_SIZE = 1000   # For shuffling the dataset
EPOCHS = 50          # Initial number of epochs; EarlyStopping will likely stop training sooner

# --- Data Paths ---
# Modify this path if your dataset is located elsewhere
# Assumes the structure provided by the Kaggle dataset version
DATASET_PATH = '/kaggle/input/deepglobe-land-cover-classification-dataset/' # Example path
METADATA_FILE = os.path.join(DATASET_PATH, 'metadata.csv')

# Assuming image/mask files are directly under DATASET_PATH based on metadata structure
# Adjust IMAGE_DIR and MASK_DIR if they are in subfolders (e.g., 'train', 'valid')
IMAGE_DIR = DATASET_PATH
MASK_DIR = DATASET_PATH

# --- Class Definitions ---

# Define the mapping from RGB color in masks to class index.
# **Important:** Verify this mapping against the dataset's official documentation.
# The order and color values must be precise.
CLASS_COLORS_RGB = {
    # RGB Tuple      : Class Index
    (0,   0,   0)   : 0,  # Unknown / Background (Black)
    (0, 255, 255)   : 1,  # Urban land (Cyan)
    (255, 255, 0)   : 2,  # Agriculture land (Yellow)
    (255, 0, 255)   : 3,  # Rangeland (Magenta/Purple)
    (0, 255, 0)     : 4,  # Forest land (Green)
    (255, 0, 0)     : 5,  # Water (Red)
    (255, 255, 255) : 6   # Barren land (White)
}

# Class names corresponding to the indices (for visualization labels)
CLASS_NAMES = [
    "Unknown", "Urban", "Agriculture", "Rangeland", "Forest", "Water", "Barren"
]

# Create TensorFlow constants for efficient mapping in the data pipeline
_color_tuples = list(CLASS_COLORS_RGB.keys())
_label_indices = list(CLASS_COLORS_RGB.values())
CLASS_COLORS_TF = tf.constant(_color_tuples, dtype=tf.uint8)
LABEL_INDICES_TF = tf.constant(_label_indices, dtype=tf.uint8)

# --- GPU Check ---
print("TensorFlow Version:", tf.__version__)
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
# Ensure TensorFlow is configured to use the GPU if available

# ## 2. Data Loading and Preprocessing
#
# Load image and mask file paths using the metadata file. Create TensorFlow Datasets (`tf.data`) for efficient loading, preprocessing, and batching.

# --- Load File Paths from Metadata ---
try:
    metadata_df = pd.read_csv(METADATA_FILE)
    print(f"Loaded metadata from {METADATA_FILE}")
    print(metadata_df.head()) # Display first few rows

    # Extract image IDs for training and validation splits
    train_ids = metadata_df[metadata_df['split'] == 'train']['image_id'].tolist()
    val_ids = metadata_df[metadata_df['split'] == 'valid']['image_id'].tolist()

    # Construct full paths to image and mask files
    # Assumes filenames are like '1000_sat.jpg' and '1000_mask.png'
    train_img_paths = [os.path.join(IMAGE_DIR, f"{img_id}_sat.jpg") for img_id in train_ids]
    train_mask_paths = [os.path.join(MASK_DIR, f"{img_id}_mask.png") for img_id in train_ids]
    val_img_paths = [os.path.join(IMAGE_DIR, f"{img_id}_sat.jpg") for img_id in val_ids]
    val_mask_paths = [os.path.join(MASK_DIR, f"{img_id}_mask.png") for img_id in val_ids]

    print(f"\nFound {len(train_img_paths)} training samples.")
    print(f"Found {len(val_img_paths)} validation samples.")

    # Basic check if a few files exist (optional, but good practice)
    missing_train_check = [p for p in train_img_paths[:5] + train_mask_paths[:5] if not os.path.exists(p)]
    missing_val_check = [p for p in val_img_paths[:5] + val_mask_paths[:5] if not os.path.exists(p)]

    if missing_train_check:
        print(f"\nWarning: Some training files not found. Example: {missing_train_check[0]}")
        print("Please verify DATASET_PATH, IMAGE_DIR, MASK_DIR, and file naming conventions.")
    if missing_val_check:
        print(f"\nWarning: Some validation files not found. Example: {missing_val_check[0]}")
        print("Please verify DATASET_PATH, IMAGE_DIR, MASK_DIR, and file naming conventions.")

except FileNotFoundError:
    print(f"Error: Metadata file not found at {METADATA_FILE}.")
    print("Cannot determine train/validation split. Please check the DATASET_PATH.")
    # Handle error appropriately: raise exception, exit, or provide default empty lists
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = [], [], [], []
except KeyError as e:
    print(f"Error: Column '{e}' not found in {METADATA_FILE}.")
    print("Metadata file must contain 'image_id' and 'split' columns.")
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = [], [], [], []
except Exception as e:
    print(f"An unexpected error occurred while loading metadata: {e}")
    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = [], [], [], []


# --- Preprocessing Functions ---

@tf.function
def map_rgb_to_labels(mask_rgb):
    """Converts an RGB mask tensor to a tensor of integer class labels.

    Args:
        mask_rgb: A TensorFlow tensor representing the RGB mask (H, W, 3), dtype=uint8.

    Returns:
        A TensorFlow tensor representing the label mask (H, W, 1), dtype=uint8.
    """
    # mask_rgb shape: (H, W, 3), dtype=uint8
    mask_shape = tf.shape(mask_rgb)
    # Initialize mask_labels with the background class index (0)
    mask_labels = tf.zeros(mask_shape[:2], dtype=tf.uint8)

    # Iterate through the defined colors (starting from index 1, as 0 is default)
    # and assign the corresponding label index where colors match.
    for i in tf.range(1, tf.shape(CLASS_COLORS_TF)[0]):
        color = CLASS_COLORS_TF[i]
        label = LABEL_INDICES_TF[i]
        # Find pixels matching the current color (returns boolean mask)
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    # Bridge\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "model = build_unet(input_shape, NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3e683",
   "metadata": {},
   "source": [
    "## 4. Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf55a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "# Use CategoricalCrossentropy because masks are one-hot encoded\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    MeanIoU(num_classes=NUM_CLASSES, name='mean_iou')\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"unet_landcover_best.keras\", save_best_only=True, monitor='val_mean_iou', mode='max'),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae509261",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history.history['mean_iou'], label='Training Mean IoU')\n",
    "    plt.plot(history.history['val_mean_iou'], label='Validation Mean IoU')\n",
    "    plt.title('Mean IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean IoU')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "print(\"\\nEvaluating the best model on the validation set:\")\n",
    "# Load the best saved model (optional, EarlyStopping might have restored it)\n",
    "# model = keras.models.load_model(\"unet_landcover_best.keras\") \n",
    "val_loss, val_accuracy, val_mean_iou = model.evaluate(val_dataset)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Mean IoU: {val_mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d18368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define intuitive colors for each class index (0-6)\n",
    "# Adjust these colors as preferred\n",
    "VIS_COLORS = [\n",
    "    (0.5, 0.5, 0.5),    # 0: Unknown (Gray)\n",
    "    (0.7, 0.1, 0.1),    # 1: Urban land (Dark Red)\n",
    "    (0.9, 0.9, 0.2),    # 2: Agriculture land (Yellow)\n",
    "    (0.9, 0.5, 0.1),    # 3: Rangeland (Orange)\n",
    "    (0.1, 0.7, 0.1),    # 4: Forest land (Green)\n",
    "    (0.1, 0.2, 0.7),    # 5: Water (Blue)\n",
    "    (0.9, 0.9, 0.9)     # 6: Barren land (Light Gray/White)\n",
    "]\n",
    "custom_cmap = ListedColormap(VIS_COLORS)\n",
    "# Create a norm for discrete colors\n",
    "norm = BoundaryNorm(np.arange(-0.5, NUM_CLASSES, 1), custom_cmap.N)\n",
    "\n",
    "# Function to display predictions\n",
    "def display_predictions(dataset, num_samples=3):\n",
    "    for image, true_mask in dataset.take(1):\n",
    "        pred_mask_prob = model.predict(image)\n",
    "        pred_mask = tf.argmax(pred_mask_prob, axis=-1)\n",
    "        true_mask_labels = tf.argmax(true_mask, axis=-1) # Convert one-hot back to labels\n",
    "\n",
    "        plt.figure(figsize=(15, 5 * num_samples))\n",
    "        for i in range(num_samples):\n",
    "            plt.subplot(num_samples, 3, i * 3 + 1)\n",
    "            plt.title(\"Input Image\")\n",
    "            plt.imshow(image[i])\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(num_samples, 3, i * 3 + 2)\n",
    "            plt.title(\"True Mask\")\n",
    "            # Use custom colormap and norm\n",
    "            plt.imshow(true_mask_labels[i], cmap=custom_cmap, norm=norm)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(num_samples, 3, i * 3 + 3)\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            # Use custom colormap and norm\n",
    "            plt.imshow(pred_mask[i], cmap=custom_cmap, norm=norm)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break # Only show predictions for one batch\n",
    "\n",
    "# Display some predictions from the validation set\n",
    "print(\"\\nDisplaying sample predictions:\")\n",
    "display_predictions(val_dataset, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
