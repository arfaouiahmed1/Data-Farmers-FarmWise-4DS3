{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "g_QtTmYHlh3r",
        "outputId": "84026656-e543-4c16-d8e9-dfd3cb0e4cb6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your kaggle.json file\")\n",
        "files.upload() # This will open a file upload dialog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7C6S05MdmAjW"
      },
      "outputs": [],
      "source": [
        "# Make directory named kaggle and copy kaggle.json file there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Change the permissions of the file.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNAxa1dTmClJ",
        "outputId": "de2bfcf4-9acf-42d3-fcc9-c706520c5424"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJb6D3NxmmXp",
        "outputId": "eea9413e-601b-49d9-9acf-3c776721b2a4"
      },
      "outputs": [],
      "source": [
        "# Replace 'username/dataset-name' with the actual command you copied\n",
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
        "# OR for competitions (you might need to accept rules on the Kaggle site first):\n",
        "# !kaggle competitions download -c competition-name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDYolnk5nlfi",
        "outputId": "f2db3d49-9743-4f52-bacb-b6292d1eeb43"
      },
      "outputs": [],
      "source": [
        "# List files to find the zip file name\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lUiksC6npxx",
        "outputId": "45815979-34a3-4afe-faa1-28d5d4638656"
      },
      "outputs": [],
      "source": [
        "!unzip new-plant-diseases-dataset.zip -d dataset_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Z4ule1owbQ",
        "outputId": "5eb7363a-725e-4d4e-d21f-a30131ce0957"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XfSOqgIHoxdc"
      },
      "outputs": [],
      "source": [
        "import os                       # for working with files\n",
        "import numpy as np              # for numerical computationss\n",
        "import pandas as pd             # for working with dataframes\n",
        "import torch                    # Pytorch module\n",
        "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
        "import torch.nn as nn           # for creating  neural networks\n",
        "from torch.utils.data import DataLoader # for dataloaders\n",
        "from PIL import Image           # for checking images\n",
        "import torch.nn.functional as F # for functions for calculating loss\n",
        "import torchvision.transforms as transforms   # for transforming images into tensors\n",
        "from torchvision.utils import make_grid       # for data checking\n",
        "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
        "from torchsummary import summary              # for getting the summary of our model\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy36sXNYo0Ke",
        "outputId": "486301aa-baba-4a2a-bc64-2e239c433fff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# --- FIND THE CORRECT BASE PATH FIRST ---\n",
        "# Use the file browser or !ls commands to confirm this path is correct in *your* Colab session!\n",
        "# It might be different depending on where exactly you unzipped.\n",
        "# Check if the 'New Plant Diseases Dataset(Augmented)' folder exists directly inside 'dataset_folder'\n",
        "# or if there's another level. Let's assume the structure from your original path is correct *after* the unzip location:\n",
        "\n",
        "base_path_in_colab = \"/content/dataset_folder/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\" #<-- ADJUST THIS PATH\n",
        "\n",
        "# Verify the base path exists\n",
        "if not os.path.exists(base_path_in_colab):\n",
        "  print(f\"ERROR: Base path not found at '{base_path_in_colab}'\")\n",
        "  print(\"Please use the file browser or !ls to find the correct path and update the 'base_path_in_colab' variable.\")\n",
        "else:\n",
        "  print(f\"Base path found: {base_path_in_colab}\")\n",
        "\n",
        "  data_dir = base_path_in_colab # Use the correct Colab path\n",
        "  train_dir = os.path.join(data_dir, \"train\") # Using os.path.join is safer\n",
        "  valid_dir = os.path.join(data_dir, \"valid\")\n",
        "\n",
        "  print(f\"Looking for train directory at: {train_dir}\")\n",
        "  print(f\"Looking for validation directory at: {valid_dir}\")\n",
        "\n",
        "  # Check if train directory exists before listing\n",
        "  if os.path.exists(train_dir):\n",
        "      diseases = os.listdir(train_dir)\n",
        "      print(\"\\nSuccessfully found train directory.\")\n",
        "      print(f\"Found {len(diseases)} classes (diseases):\")\n",
        "      print(diseases)\n",
        "  else:\n",
        "      print(f\"\\nERROR: Train directory not found at '{train_dir}'\")\n",
        "      print(\"Check the 'base_path_in_colab' and the unzipped folder structure.\")\n",
        "\n",
        "  # You can also check the validation directory\n",
        "  if os.path.exists(valid_dir):\n",
        "    print(\"\\nSuccessfully found validation directory.\")\n",
        "  else:\n",
        "    print(f\"\\nERROR: Validation directory not found at '{valid_dir}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDE_aHTgo3MX",
        "outputId": "6fc00511-9382-4578-8adf-b45cee15f417"
      },
      "outputs": [],
      "source": [
        "print(diseases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ftIrj5bqJhI",
        "outputId": "68ddf91c-4aae-4968-8dfd-a6778cb2ab88"
      },
      "outputs": [],
      "source": [
        "print(\"Total disease classes are: {}\".format(len(diseases)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gA9qa3NwqeYQ"
      },
      "outputs": [],
      "source": [
        "plants = []\n",
        "NumberOfDiseases = 0\n",
        "for plant in diseases:\n",
        "    if plant.split('___')[0] not in plants:\n",
        "        plants.append(plant.split('___')[0])\n",
        "    if plant.split('___')[1] != 'healthy':\n",
        "        NumberOfDiseases += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQA1W49WqhdR",
        "outputId": "f4d3a4d2-2784-4dd2-d485-0806f5fec1f0"
      },
      "outputs": [],
      "source": [
        "# unique plants in the dataset\n",
        "print(f\"Unique Plants are: \\n{plants}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCPHtM3vqkBq",
        "outputId": "cb1709fe-fc78-4e5f-c6f2-beebdffbd373"
      },
      "outputs": [],
      "source": [
        "# number of unique plants\n",
        "print(\"Number of plants: {}\".format(len(plants)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsdlXTz3qmFe",
        "outputId": "6d81a0f2-06da-4ead-d66e-faa642ecee00"
      },
      "outputs": [],
      "source": [
        "# number of unique diseases\n",
        "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CAruvbuuqoAA",
        "outputId": "ba7f2c95-737d-41c6-dc3c-c23502728ab2"
      },
      "outputs": [],
      "source": [
        "# Number of images for each disease\n",
        "nums = {}\n",
        "for disease in diseases:\n",
        "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
        "\n",
        "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
        "\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4NC9-RDsqqGK",
        "outputId": "fb97958f-e018-4677-8926-1af963b47446"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plant_names = []\n",
        "Len = []\n",
        "for i in diseases:\n",
        "    plant_names.append(i)\n",
        "    imgs_path = os.listdir(train_dir + \"/\" + i)\n",
        "    Len.append(len(imgs_path))\n",
        "\n",
        "Len.sort(reverse=True)\n",
        "\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "plt.figure(figsize=(20,20),dpi=200)\n",
        "ax = sns.barplot(x= Len, y= plant_names, palette=\"Greens\")\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7MXzov8qsaG",
        "outputId": "a4782e00-4f58-4b6d-d04c-8440a062d2d4"
      },
      "outputs": [],
      "source": [
        "n_train = 0\n",
        "for value in nums.values():\n",
        "    n_train += value\n",
        "print(f\"There are {n_train} images for training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz7S-pWcgH25"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1l2WOMz5qwE1"
      },
      "outputs": [],
      "source": [
        "# datasets for validation and training\n",
        "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "valid = ImageFolder(valid_dir, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIZXUyxsqxnR",
        "outputId": "4aad4c1a-2d75-44ea-bfb8-4afe23af5863"
      },
      "outputs": [],
      "source": [
        "img, label = train[0]\n",
        "print(img.shape, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGFVBDxCqzSQ",
        "outputId": "ec9f2978-deb4-4107-c91f-ac266c120a1f"
      },
      "outputs": [],
      "source": [
        "# total number of classes in train set\n",
        "len(train.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ngGdlTQ5q0wU"
      },
      "outputs": [],
      "source": [
        "# for checking some images from training dataset\n",
        "def show_image(image, label):\n",
        "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
        "    plt.imshow(image.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "U9ATTRMmq2Zh",
        "outputId": "3070d77a-7aa4-4a86-bf53-fc89df3e53b7"
      },
      "outputs": [],
      "source": [
        "show_image(*train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "79yxHt4pq4ee",
        "outputId": "b8a805c6-cd1b-4a67-e2c7-379a1c470477"
      },
      "outputs": [],
      "source": [
        "show_image(*train[70000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a_eiBAJq7Tp",
        "outputId": "f8b55040-e883-4c73-9c46-e49dcb27bf3d"
      },
      "outputs": [],
      "source": [
        "# Setting the seed value\n",
        "random_seed = 7\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nbfyY-XQq-BJ"
      },
      "outputs": [],
      "source": [
        "# setting the batch size\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8F1ih5lprA92"
      },
      "outputs": [],
      "source": [
        "# DataLoaders for training and validation\n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OhwW4uQirCpa"
      },
      "outputs": [],
      "source": [
        "# helper function to show a batch of training instances\n",
        "def show_batch(data):\n",
        "    for images, labels in data:\n",
        "        fig, ax = plt.subplots(figsize=(30, 30))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "qlgCJQfirEHJ",
        "outputId": "d3227b3b-3ed6-4264-b66a-9ab7f18e9a22"
      },
      "outputs": [],
      "source": [
        "# Images for first batch of training\n",
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ofVWHv0gVbY"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6sRcxGRhrFbE"
      },
      "outputs": [],
      "source": [
        "# for moving data into GPU (if available)\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available:\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "# for moving data to device (CPU or GPU)\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "# for loading in the device (GPU if available else CPU)\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov16Ya1ArP6Y",
        "outputId": "2849fa70-4eb4-465a-aab7-a5bd3d192414"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tmocmgWNrSoE"
      },
      "outputs": [],
      "source": [
        "# Moving data into GPU\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MsY0s55UrUYa"
      },
      "outputs": [],
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        return self.relu2(out) + x # ReLU can be applied before or after adding the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "I9bA9WogrXOE"
      },
      "outputs": [],
      "source": [
        "# for calculating the accuracy\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "\n",
        "# base class for the model\n",
        "class ImageClassificationBase(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate prediction\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        preds = torch.argmax(out, dim=1)      # Get class predictions\n",
        "        return {\n",
        "            \"val_loss\": loss.detach(),\n",
        "            \"val_accuracy\": acc,\n",
        "            \"preds\": preds.detach(),  # Add predictions\n",
        "            \"labels\": labels.detach() # Add ground truth\n",
        "        }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n",
        "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
        "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lNNB-mbgraGx"
      },
      "outputs": [],
      "source": [
        "# convolution block with BatchNormalization\n",
        "def ConvBlock(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "             nn.BatchNorm2d(out_channels),\n",
        "             nn.ReLU(inplace=True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(4))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "# resnet architecture\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_diseases):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, 64)\n",
        "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64\n",
        "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
        "\n",
        "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
        "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
        "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                       nn.Flatten(),\n",
        "                                       nn.Linear(512, num_diseases))\n",
        "\n",
        "    def forward(self, xb): # xb is the loaded batch\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8Rc8skhrd5b",
        "outputId": "03dc0ece-6709-4e8b-e8f9-564dd4f79af1"
      },
      "outputs": [],
      "source": [
        "# defining the model and moving it to the GPU\n",
        "model = to_device(ResNet9(3, len(train.classes)), device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zhgf9yPrgDl",
        "outputId": "d92881ea-5617-46f2-82ba-c9819f6f615f"
      },
      "outputs": [],
      "source": [
        "# getting summary of the model\n",
        "INPUT_SHAPE = (3, 256, 256)\n",
        "print(summary(model.cuda(), (INPUT_SHAPE)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6HGRzR3glIL"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KmpihQ6AwHzL"
      },
      "outputs": [],
      "source": [
        "# for training\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "\n",
        "    # Combine predictions and labels across batches\n",
        "    preds = torch.cat([x['preds'] for x in outputs]).cpu().numpy()\n",
        "    labels = torch.cat([x['labels'] for x in outputs]).cpu().numpy()\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "\n",
        "    # Get original metrics\n",
        "    result = model.validation_epoch_end(outputs)\n",
        "    result['confusion_matrix'] = cm\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n",
        "                grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # scheduler for one cycle learniing rate\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # recording and updating learning rates\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "\n",
        "        # validation\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5qTIaYLwRdt",
        "outputId": "0d74ac9b-3d78-4e15-f561-8f4819c860e1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = [evaluate(model, valid_dl)]\n",
        "history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PqeFxHk6wVm3"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "max_lr = 0.01\n",
        "grad_clip = 1.0\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR0WsYM1wn3G",
        "outputId": "6c4fdd0f-e312-482c-c03d-0465f054392c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history += fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl,\n",
        "                             grad_clip=grad_clip,\n",
        "                             weight_decay=1e-4,\n",
        "                             opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0YMjLNVgzwN"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nw1xyQq3wqga"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_accuracy'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "def plot_losses(history):\n",
        "    # Convert CUDA tensors to CPU floats\n",
        "    train_losses = []\n",
        "    for x in history:\n",
        "        tl = x.get('train_loss')\n",
        "        if tl is not None:\n",
        "            if isinstance(tl, torch.Tensor):\n",
        "                tl = tl.detach().cpu().item()  # Convert to Python float\n",
        "            train_losses.append(tl)\n",
        "        else:\n",
        "            train_losses.append(None)\n",
        "\n",
        "    val_losses = []\n",
        "    for x in history:\n",
        "        vl = x['val_loss']\n",
        "        if isinstance(vl, torch.Tensor):\n",
        "            vl = vl.detach().cpu().item()\n",
        "        val_losses.append(vl)\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(train_losses, '-bx', label='Training')\n",
        "    plt.plot(val_losses, '-rx', label='Validation')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.');\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "t4vrJzqX4I40",
        "outputId": "e8e0d30f-d8dc-46f4-9531-512d32c4be11"
      },
      "outputs": [],
      "source": [
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "JvQYIASv4JYH",
        "outputId": "e0c831d3-093b-4ba3-db01-492ef3fe8469"
      },
      "outputs": [],
      "source": [
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "8TKsu8Kp4LVV",
        "outputId": "fcfe8eb6-5e3e-4928-ad6d-7bbe147c9b79"
      },
      "outputs": [],
      "source": [
        "plot_lrs(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "44pasyBkxk1a",
        "outputId": "1d6908ba-503c-41ca-ec5a-71218d3b9267"
      },
      "outputs": [],
      "source": [
        "# After training, get the confusion matrix from the last validation result\n",
        "cm = history[-1]['confusion_matrix']\n",
        "plot_confusion_matrix(cm, class_names=train.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTnhmpyGhAiM"
      },
      "source": [
        "# Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "RE581cbq4OkB"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "test_dir = \"/content/dataset_folder/test\"\n",
        "test = ImageFolder(test_dir, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF4OVCXI4RS1",
        "outputId": "b9d64fd6-84f4-472e-cf7d-2c2893c92b92"
      },
      "outputs": [],
      "source": [
        "test_images = sorted(os.listdir(test_dir + '/test')) # since images in test folder are in alphabetical order\n",
        "test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MHXCXY6mV_4p"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    \"\"\"Converts image to array and return the predicted class\n",
        "        with highest probability\"\"\"\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "\n",
        "    return train.classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "NTsbosWJWCSi",
        "outputId": "3081dbb4-86fa-4378-ed93-368c66e4c666"
      },
      "outputs": [],
      "source": [
        "# predicting first image\n",
        "img, label = test[0]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', test_images[0], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjU3tSfxWE0I",
        "outputId": "99f2d794-a9af-4112-b433-b5b890571c75"
      },
      "outputs": [],
      "source": [
        "# getting all predictions (actual label vs predicted)\n",
        "for i, (img, label) in enumerate(test):\n",
        "    print('Label:', test_images[i], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TYqAIW6hHij"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fphPTMBDhJI9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4YSdPmrMhtgq"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'model_full.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eUQpT3jzh3Sj",
        "outputId": "e85927c9-dd74-429d-d4e6-3c6290cd85b1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('model.pt')\n",
        "files.download('model_full.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
